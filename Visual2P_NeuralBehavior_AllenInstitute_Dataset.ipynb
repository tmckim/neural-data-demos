{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "N_dUxErHv7IL",
        "xEXcIJ333w8Z",
        "Vy0StLLtwP5-",
        "AquVjQnDesuc",
        "nk5yoQnwmP1Z",
        "Sa2KzrKPPNnc",
        "B6SEKGKKnXWk",
        "FCZ0Y1Sajx23",
        "7FxPpas9Vue_",
        "WMxssFCPwCjL",
        "MCo_El0Jw535",
        "EuOjuBKvxKZv",
        "B57c079ay53O"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmckim/neural-data-demos/Visual2P_NeuralBehavior_AllenInstitute_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "7ouiQYZCUBeP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRmCxp91P0Pt"
      },
      "source": [
        "# Allen Institute Visual Behavior 2P Dataset - Plotting Neural + **Behavioral** Data Demo\n",
        "\n",
        "\n",
        "Today, we will work with this dataset and plot additional behavioral variables along with the calcium signal from neurons recorded while mice performed a visual discrimination task.\n",
        "\n",
        "\n",
        "This notebook will help us investigate data collected from the [Visual Behavior 2P](https://portal.brain-map.org/explore/circuits/visual-behavior-2p) dataset from the Allen Brain Institute.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4KPaiNeQBhE"
      },
      "source": [
        "____\n",
        "# Learning Objectives\n",
        "\n",
        "## At the end of this notebook, you'll be able to:\n",
        "* Plot calcium imaging data based on experimental conditions üî¨ üîé üìà\n",
        "* Examine the relationship between neuronal responses and behavior üß† üèÉ üëÄ üí¶\n",
        "* Understand differences in data format  üí≠ üìì\n",
        "* Understand how to use common Python packages for data visualization üêç üíª\n",
        "* Apply best practices for plotting data üìä üì£\n",
        "\n",
        "**<font color=\"red\" size=4> IMPORTANT: This notebook is READ-ONLY. To edit and run this notebook, follow the steps in the next section.</font>**\n",
        "______"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU3zB5EtQlYz"
      },
      "source": [
        "____\n",
        "## üíæ Before you start - Save this notebook!\n",
        "<a name=\"save\"></a>\n",
        "\n",
        "When you open a new Colab notebook from the WebCampus (like you hopefully did for this one), you cannot save changes. So it's  best to store the Colab notebook in your personal drive `\"File > Save a copy in drive...\"` **before** you do anything else.\n",
        "\n",
        "The file will open in a new tab in your web browser, and it is automatically named something like: \"**Copyof Visual2P_NeuralBehavior_AllenInstitute_Dataset.ipynb**\". You can rename this to just the title of the assignment \"**Visual2P_NeuralBehavior_AllenInstitute_Dataset.ipynb**\". Make sure you do keep an informative name (like the name of the assignment) to help you be able to come back to this after you complete this part of the assignment.\n",
        "\n",
        "**Where does the notebook get saved in Google Drive?**\n",
        "\n",
        "By default, the notebook will be copied to a folder called ‚ÄúColab Notebooks‚Äù at the root (home) directory of your Google Drive.\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python üêç  & Colab üìì\n",
        "<a name=\"section0\"></a>\n",
        "\n",
        "Welcome to Google Colab! We'll be working in Colab for this introductory Python course.\n",
        "\n",
        "</br>\n",
        "</br>\n",
        "<img src=\"https://miro.medium.com/max/986/1*pimj8lXWwZnqLs2xVCV2Aw.png\" width=500>\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "\n",
        "## What is Colab?\n",
        "Colab is a browser-based environment - you can develop, run, and share code directly on your browser without having to install any software or libraries on your computer. Additionally, code written and run from colab runs on google's cloud computers, so you aren't limited by your laptop's speed or compute power. üì∂\n",
        "\n",
        "</br>\n",
        "\n",
        "**<font color='red'>Note: One downside of Colab is that if you turn off your computer, are idle, or refresh the page, your current runtime is lost. You will need to run the notebook from the beginning in order to redo any variables, functions, or operations you have performed.</br></br> You can more easily rerun your notebook by clicking Runtime>>Run all, or Runtime>>Run before at the top of the page. This will attempt to run all of your current cells (until one gets an error) or  all of the cells above the current cell your cursor is on. </font>**\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "Colab can be especially helpful for data science tasks, because it gives you a space to write code, generate/view graphs, and organize your thought process.  For those of you who have used Jupyter before, colab acts a simple browser-based Jupyter notebook. We'll be using colab with Python, but colab can be used with a variety of different coding languages.\n",
        "\n",
        "</br>\n",
        "\n",
        "A Colab notebook (a file like this one) consists of cells, snippets of code or text that you can create, edit, and move around to keep things organized. These cells can be:\n",
        "\n",
        "*   **text cells** üî†\n",
        "<br>or<br>\n",
        "*   **code cells** üíª\n",
        "\n",
        "You can **double click** <img src='https://miro.medium.com/v2/resize:fit:280/0*oa0XcvM99Y5clDsj.png' alt='mouse cursor images' height='25px'>\n",
        "on a cell in order\n",
        "to edit it.\n",
        "\n",
        "-----\n",
        "</br>"
      ],
      "metadata": {
        "id": "ww-e_hJ8TbRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üèã Coding Exercise\n",
        "\n",
        "<a name=\"exercise1\"></a>"
      ],
      "metadata": {
        "id": "EGwABaNOTtUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Task: Run this cell\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "Run the cell below by clicking on the 'play arrow button' ‚ñ∂ in the top left corner, or using the keys: shift + return (mac) or shift + enter (pc)\n",
        "</div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "cellView": "form",
        "id": "3aaBXvMUTy_y",
        "outputId": "fc79ce45-c60b-4a5a-a55c-ac5697f35250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "Run the cell below by clicking on the 'play arrow button' ‚ñ∂ in the top left corner, or using the keys: shift + return (mac) or shift + enter (pc)\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In Python, anything with a \"#\" in front of it is code annotation,\n",
        "# and is not read by the computer.\n",
        "# You can run a cell (this box) by pressing shift-enter or shift-return.\n",
        "# Click in this cell and then press shift and enter simultaneously.\n",
        "# This print function below allows us to generate a message.\n",
        "\n",
        "print('Nice work!')"
      ],
      "metadata": {
        "id": "x5VQT-NcXyuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "J66B1v7tPOGA"
      },
      "source": [
        "---\n",
        "# Allen Institute Visual Behavior 2P Dataset:  Overview\n",
        "### This dataset consists of neural activity measured with 2-photon calcium imaging in the visual cortex of mice performing an image change detection task. In this task, mice learn to report changes in stimulus identity by licking a spout to earn a water reward.\n",
        "\n",
        "\n",
        "# Dataset Notes\n",
        "\n",
        "The entire dataset includes neural and behavioral measurements from:\n",
        "\n",
        "*   107 mice üê≠\n",
        "*   4787 behavior training sessions üëÄ\n",
        "*   704 *in vivo* imaging sessions üî¨\n",
        "*   50,482 cortical cells üß†\n",
        "\n",
        "The data are openly accessible, and include information about all recorded timeseries, behavioral events, and experimental data in a standard data format: [Neurodata Without Borders (NWB)](https://www.nwb.org/nwb-neurophysiology/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "![](https://github.com/tmckim/NTC_2024/blob/main/img/task_image.png?raw=1)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OHk_mGpGX_P1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Behavioral Task\n",
        "##### In some sessions, the mice perform the task with familiar images they have seen many times during training. In other sessions, mice perform the task with novel images.\n",
        "##### During 2-photon imaging sessions, 5% of stimulus presentations are randomly omitted, allowing us to examine the effect of unexpected events on neural activity.\n",
        "##### The same population of cells is imaged over multiple days with varying sensory and behavioral conditions.\n",
        "\n",
        "![](https://github.com/tmckim/NTC_2024/blob/main/img/experiment_overview.png?raw=1)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vkA5UmUiYCNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Calcium Imaging\n",
        "##### Multiple cortical areas and depths were measured concurently in each session, at a sample rate of 11Hz.\n",
        "##### In the full dataset, data was collected from excitatory and inhibitory neural populations.\n",
        "![](https://github.com/tmckim/NTC_2024/blob/main/img/imaging_overview.png?raw=1)\n",
        "\n",
        "_______"
      ],
      "metadata": {
        "id": "pp2dEFIXYFFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚ùó Check out a recent paper published in Neuron on this dataset: [Behavioral strategy shapes activation of the Vip-Sst disinhibitory circuit in visual cortex](https://www.sciencedirect.com/science/article/pii/S0896627324000928)\n",
        "---"
      ],
      "metadata": {
        "id": "q2V6EEoAb9FG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we are going to focus on the relationship between neural data and behavior metrics.\n",
        "\n",
        "![](https://allenswdb.github.io/_images/Trial_diagram.png)\n",
        "<br>\n",
        "Image [source](https://allenswdb.github.io/physiology/ophys/visual-coding/vc2p-background.html)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Dh1HgtA4UvDf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Dk_3p-OcPOGo"
      },
      "source": [
        "# Setup and import files üß∞ üõ†"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import allensdk\n",
        "Allen Software Development Kit (`allensdk`) - source code for reading and processing Allen Brain Atlas data. Works with:\n",
        "* Allen Brain Observatory\n",
        "* Cell Types Database\n",
        "* Mouse Brain Connectivity Atlas\n",
        "\n",
        "https://allensdk.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "p2Vj_QIMVENQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allensdk"
      ],
      "metadata": {
        "id": "3lEV6kKjVC-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNi2XorrRNbD"
      },
      "source": [
        "## Step 2: Set up coding environment: üìö Python Libraries\n",
        "<a name=\"pylibs\"></a>\n",
        "\n",
        "Each time we start an analysis in Python, we must import the necessary code packages. If you're running this notebook in Colab, the cells below will install packages into your coding environment -- these are *not* installed on your computer.\n",
        "\n",
        "Like in many computer languages, the beauty of Python is that other people have spent much time developing useful code that they have tested robustly and wish to share with others. These are called libraries or packages.  We can import popular packages into the Python/Colab environment and if the package has not already been installed on our version of Python, we can easily install the package and use it.\n",
        "\n",
        "(In Colab, or in a linux environment if you run Python locally, we can easily install new packages using ```!pip install [PYTHON PACKAGE]```)\n",
        "\n",
        "For this Colab notebook we will be working with four packages that typically come pre-installed on most versions of Python. They are:\n",
        "\n",
        "\n",
        "- **[numpy](https://numpy.org/doc/stable/user/index.html)**: A library for working with numerical lists, called arrays\n",
        "- **[pandas](https://pandas.pydata.org/docs/user_guide/index.html)**: A library for working with two dimenional lists, called dataframes\n",
        "- **[matplotlib](https://matplotlib.org/stable/tutorials/index)**: A package for plotting, commonly used in tandem with numpy and pandas\n",
        "- **[seaborn](https://seaborn.pydata.org/tutorial.html)**: A package for plotting, commonly used in tandem with pandas\n",
        "\n",
        "</br><img src=\"https://miro.medium.com/max/765/1*cyXCE-JcBelTyrK-58w6_Q.png\" width=200> <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1200px-Pandas_logo.svg.png\" width=200> </br><img src=\"https://matplotlib.org/stable/_static/logo_dark.svg\" width=200> <img src=\"https://seaborn.pydata.org/_images/logo-wide-lightbg.svg\" width=200> </br></br>\n",
        "We can import these libraries (or certain classes/functions from these libraries) into our local runtime using the following code. The nicknames I used (`np`, `plt`, `np`, and `sns`)  are pretty standard nicknames that most Python programmers use, though you could use anything."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our plotting package from matplotlib and shorten it to plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import plotting package seaborn and shorten to sns\n",
        "import seaborn as sns\n",
        "\n",
        "# Import numpy and shorten it to np\n",
        "import numpy as np\n",
        "\n",
        "# Import pandas for working with databases and shorten it to pd\n",
        "import pandas as pd\n",
        "\n",
        "# Set default display column number\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "# Specify that all plots will happen inline & in high resolution\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Import the dataset tools from allensdk\n",
        "from allensdk.brain_observatory.behavior.behavior_project_cache import VisualBehaviorOphysProjectCache\n",
        "\n",
        "import allensdk\n",
        "import pkg_resources # deprecated and no longer needs to be explicitly imported here (but note used below!)\n",
        "print('allensdk version 2.10.2 or higher is required, you have {} installed'.format(pkg_resources.get_distribution(\"allensdk\").version))"
      ],
      "metadata": {
        "id": "gZrpSTIUVLFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TbSJ3wUeeT"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zBeQQriT90Y"
      },
      "outputs": [],
      "source": [
        "# Define the path to the data we want to retrieve\n",
        "output_dir = '/path/to/vbo'\n",
        "cache = VisualBehaviorOphysProjectCache.from_s3_cache(cache_dir=output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## The data from the experiment is in separate tables"
      ],
      "metadata": {
        "id": "2ERvSf03VlXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get metadata tables\n",
        "behavior_session_table = cache.get_behavior_session_table()\n",
        "ophys_session_table = cache.get_ophys_session_table()\n",
        "ophys_experiment_table = cache.get_ophys_experiment_table()\n",
        "\n",
        "# Print number of items in each table for all imaging and behavioral sessions\n",
        "print('Number of behavior sessions = {}'.format(len(behavior_session_table)))\n",
        "print('Number of ophys sessions = {}'.format(len(ophys_session_table)))\n",
        "print('Number of ophys experiments = {}'.format(len(ophys_experiment_table)))"
      ],
      "metadata": {
        "id": "dXCL8RcmEUKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Behavior session table: full training history of each mouse and is organized by `behavior_session_id`.\n",
        "  * `Session_types` under 2P begin with `OPHYS_` and have an `ophys_session_id` if the data passed quality control and are available for analysis"
      ],
      "metadata": {
        "id": "zHuax-jBE88P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "behavior_session_table"
      ],
      "metadata": {
        "id": "f5lgaKypFymJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get size info\n",
        "behavior_session_table.shape"
      ],
      "metadata": {
        "id": "ihHpym8WMxev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ophys session table: metadata for each imaging session\n",
        "  * organized by `ophys_session_id`"
      ],
      "metadata": {
        "id": "KvvP5Mp9Fwes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ophys_session_table"
      ],
      "metadata": {
        "id": "6BDTnjlaF3i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get size info\n",
        "ophys_session_table.shape"
      ],
      "metadata": {
        "id": "5GTp_Yn5M0cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ophys experiment table: metadata for each imaging plane in each session\n",
        "  * organized by `ophys_experiment_id`\n",
        "  * includes all data as in the `ophys_session_table` + info specific to the imaging plane: `imaging_depth` and `targeted_structure`"
      ],
      "metadata": {
        "id": "AZPUZa1hFx9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ophys_experiment_table"
      ],
      "metadata": {
        "id": "DWbyxR7jEUhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get size info\n",
        "ophys_experiment_table.shape"
      ],
      "metadata": {
        "id": "Jp9MbFqWM180"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Examining the data based on trial types:\n",
        "* hit\n",
        "* miss\n",
        "* false alarm\n",
        "* correct rejection"
      ],
      "metadata": {
        "id": "ZY9UYVWF1yd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will select responses to familiar images- ophys 1 images"
      ],
      "metadata": {
        "id": "0nIVyOCI2FEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sessions = ophys_experiment_table.query('session_type == \"OPHYS_1_images_A\"')\n",
        "sessions"
      ],
      "metadata": {
        "id": "bCOSm6D23f96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many mice?\n",
        "selected_session_info = sessions.mouse_id.unique()\n",
        "\n",
        "print('Number of mice: {}'.format(len(selected_session_info)))\n",
        "\n",
        "# How many brain regions?\n",
        "selected_session_info = sessions.targeted_structure.unique()\n",
        "\n",
        "print('Number of brain regions: {}'.format(len(selected_session_info)))"
      ],
      "metadata": {
        "id": "f28AKi-Y0FkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ophys_experiment_id\n",
        "example_id = sessions[sessions.index == 946476556]\n",
        "example_id"
      ],
      "metadata": {
        "id": "_0HrAL6s44fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many ids could we chose from?\n",
        "len(sessions.index.unique())"
      ],
      "metadata": {
        "id": "jEnwjQuqyfkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've pre-selected an experiment id to use below"
      ],
      "metadata": {
        "id": "Spah5bH_XUQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select an id that used ophys 1 images A experiment\n",
        "experiment_id = 946476556\n",
        "print('getting experiment data for experiment_id {}'.format(experiment_id))\n",
        "\n",
        "# this is new\n",
        "experiment_dataset = cache.get_behavior_ophys_experiment(experiment_id)"
      ],
      "metadata": {
        "id": "9I9ygAn05LSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal: Combine various sources of data to create a plot that includes behavioral üèÉ üëÄ üí¶ and neural üß† data\n",
        "\n",
        "\n",
        "* `dff_traces`- calcium florescence signal\n",
        "* `events` - timing and magnitude of calcium signals\n",
        "  * exclude prolonged calcium transients that may contaminate neural responses to subsequent stimuli\n",
        "* `events`\n",
        "* `running_speed`\n",
        "* `pupil_area`\n",
        "* `stimulus_presentations`"
      ],
      "metadata": {
        "id": "syzTlyy9L0Pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Review: Stimulus Presentations\n",
        "\n",
        "Which images were shown on each trial?\n",
        "\n",
        "\n",
        "There are some conditions we aren't interested in (initial_gray_screen_5min, natural_movie, etc)"
      ],
      "metadata": {
        "id": "Kay5Njn_Xk7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What images were shown?\n",
        "stimulus_presentations = experiment_dataset.stimulus_presentations\n",
        "stimulus_presentations"
      ],
      "metadata": {
        "id": "IvLwkFQW9Pz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the change detection trials only\n",
        "stimulus_presentations = experiment_dataset.stimulus_presentations[\n",
        "    experiment_dataset.stimulus_presentations.stimulus_block_name.str.contains('change_detection')]\n",
        "\n",
        "# Show the first 5 rows\n",
        "stimulus_presentations.head()"
      ],
      "metadata": {
        "id": "9YaoMxF791oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##  üîÉ  Transform Calcium Imaging Data from Wide to Long Format\n",
        "\n",
        "<u> **Note on data format**</u>: This dataset is in wide format, where each row would represent a different `cell_id `and all data for that cell would be contained in the columns of a single row. Focus on the `dff` column (which has multiple values in it) in the dataframe below"
      ],
      "metadata": {
        "id": "1SEdw_7oYC8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the calcium imaging data - in wide format\n",
        "experiment_dataset.dff_traces"
      ],
      "metadata": {
        "id": "PTjISYnxX0HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßπ Tidy Data\n",
        "However, sometimes datasets can be easier to work with in long-format, or [`tidy`](https://aeturrell.github.io/python4DS/data-tidy.html) data. <br>\n",
        "To demonstrate this, we will transform the data format to be in long format.\n",
        "\n",
        "We will run the function below to do this- it will take several seconds to run"
      ],
      "metadata": {
        "id": "7VVbMqAbNr7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Function to transfrom data from wide format into long format\n",
        "def get_cell_timeseries_dict(dataset, cell_specimen_id):\n",
        "    '''\n",
        "    For a given cell_specimen ID, this function creates a dictionary with the following keys\n",
        "    * timestamps: ophys timestamps\n",
        "    * cell_roi_id\n",
        "    * cell_specimen_id\n",
        "    * dff\n",
        "    This is useful for generating a tidy dataframe\n",
        "    arguments:\n",
        "        session object\n",
        "        cell_specimen_id\n",
        "    returns\n",
        "        dict\n",
        "    '''\n",
        "    dff_row = dataset.dff_traces.loc[cell_specimen_id]\n",
        "\n",
        "    num_timestamps = len(dataset.ophys_timestamps)\n",
        "\n",
        "    return {\n",
        "        'timestamps': dataset.ophys_timestamps,\n",
        "        'cell_roi_id': np.full(num_timestamps, dff_row['cell_roi_id']),\n",
        "        'cell_specimen_id': np.full(num_timestamps, cell_specimen_id),\n",
        "        'dff': dff_row['dff']\n",
        "    }\n",
        "\n",
        "# ---- Main tidy dataframe creation ----\n",
        "\n",
        "# Get list of cell_specimen_ids\n",
        "cell_specimen_ids = experiment_dataset.dff_traces.index\n",
        "\n",
        "# Generate list of dfs, one per cell\n",
        "cell_timeseries = [\n",
        "    pd.DataFrame(get_cell_timeseries_dict(experiment_dataset, cell_specimen_id))\n",
        "    for cell_specimen_id in cell_specimen_ids\n",
        "]\n",
        "\n",
        "# Concatenate into one tidy df\n",
        "experiment_dataset.tidy_dff_traces = pd.concat(cell_timeseries, ignore_index=True)\n",
        "\n",
        "# Review the df\n",
        "experiment_dataset.tidy_dff_traces.sample(5, random_state=42)"
      ],
      "metadata": {
        "id": "216bpJfTdh0g",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ùì‚ùóErrors & Troubleshooting\n",
        "\n",
        "If your run into issues with running the function, import the datafile in the long format by loading it in here\n",
        "\n",
        "## Import Data File - Optional\n",
        "\n"
      ],
      "metadata": {
        "id": "N_dUxErHv7IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the file and make accessible to this notebook session\n",
        "!pip install -U gdown\n",
        "import gdown\n",
        "\n",
        "gdown.download(id=\"1hEWrIOgAXDebIWybRfRLkizhsyD1MbcM\", output=\"tidy_dff_traces.parquet\", quiet=False)"
      ],
      "metadata": {
        "id": "CFE0-Q3gvkr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the datafile\n",
        "tidy_dff_traces = pd.read_parquet('tidy_dff_traces.parquet')"
      ],
      "metadata": {
        "id": "WUaOxondO4N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add it to where we reference it later\n",
        "experiment_dataset.tidy_dff_traces = tidy_dff_traces"
      ],
      "metadata": {
        "id": "DKHVDgSYPFUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional - Walkthrough of function\n"
      ],
      "metadata": {
        "id": "xEXcIJ333w8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested in walking through what the above function is doing step by step, review the code cells below."
      ],
      "metadata": {
        "id": "0uw_u5593NfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first we need to see what cell specimen ids we have to choose from\n",
        "experiment_dataset.dff_traces.head()"
      ],
      "metadata": {
        "id": "2ZV4mjlt3SMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose one to test out the code within the function- cell specimen id is an input to the function\n",
        "# Find the cell_roi_id corresponding to the cell_specimen_id and then repeat that number the length of rows we have for the ophys timestamps\n",
        "cell_specimen_id = 1086677732\n",
        "\n",
        "# np.full(shape, fill_value)\n",
        "test = np.full(len(experiment_dataset.ophys_timestamps), experiment_dataset.cell_specimen_table.loc[cell_specimen_id, 'cell_roi_id'])\n",
        "\n",
        "test"
      ],
      "metadata": {
        "id": "VQb4Ru_Z3Yi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the same thing but using the cell_specimen_id - this is used in the broader loop and defined there each time\n",
        "\n",
        "# np.full(shape, fill_value)\n",
        "test_cell_specimen_id = np.full(len(experiment_dataset.ophys_timestamps), cell_specimen_id)\n",
        "\n",
        "test_cell_specimen_id"
      ],
      "metadata": {
        "id": "rgxvn7nj3ej8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the dff trace data\n",
        "experiment_dataset.dff_traces.loc[cell_specimen_id]['dff']"
      ],
      "metadata": {
        "id": "X8rEVtnj3kEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above values are all arrays (dict) and then get put into a dataframe"
      ],
      "metadata": {
        "id": "O3nTzU-h3lxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Visualization üìà üìä\n",
        "Define a function to plot for each type of data:\n",
        "\n",
        "* each stimulus as a colored vertical bar<br>\n",
        "* running speed - (cm/s)\n",
        "* licks/rewards - timing of lick and reward\n",
        "* pupil area - (px sq)\n",
        "* neural responses (dF/F) - calcium florescence signal <br>\n",
        "\n",
        "\n",
        "\n",
        "This enables us to just reuse the code to make the plot below, but select different cells to plot!"
      ],
      "metadata": {
        "id": "DSLEwwo_3rym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Prep: Defining Colors for Each Image\n",
        "Data preparation for plotting - we will add a list of colors for each image. This will appear as a vertical bar on our plots to indicate the time the image was shown, and to visually identify when images changed or stayed the same."
      ],
      "metadata": {
        "id": "r9ot_orMSw16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Code - Image Colors for Plot\n",
        "# Makes a color for each image name for plots (vertical bars)\n",
        "\n",
        "# Create a list of all unique stimuli presented in this experiment\n",
        "unique_stimuli = [stimulus for stimulus in stimulus_presentations['image_name'].unique() if stimulus != 'omitted']\n",
        "\n",
        "# Create a colormap with each unique image having its own color\n",
        "colormap = {image_name: sns.color_palette('colorblind')[image_number] for image_number, image_name in enumerate(np.sort(unique_stimuli))}\n",
        "colormap['omitted'] = np.nan # assign gray to omitted\n",
        "\n",
        "# Add the colors for each image to the stimulus presentations table in the dataset\n",
        "stimulus_presentations['color'] = stimulus_presentations['image_name'].map(lambda image_name: colormap[image_name])"
      ],
      "metadata": {
        "id": "5O0FqOpp38sD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is called [list comprehension](https://www.geeksforgeeks.org/python-list-comprehension/)"
      ],
      "metadata": {
        "id": "hKuX_VkuS-GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Code - Defining Functions to Plot\n",
        "def plot_stimuli(trial, ax):\n",
        "    '''\n",
        "    plot stimuli as colored bars on specified axis\n",
        "    '''\n",
        "    # Fixup type for use in query.\n",
        "    stimulus_presentations['omitted'] = stimulus_presentations['omitted'].astype('bool')\n",
        "    stimuli = stimulus_presentations.query('end_time >= {} and start_time <= {} and not omitted'.format(float(trial['start_time']), float(trial['stop_time'])))\n",
        "    for idx, stimulus in stimuli.iterrows():\n",
        "        ax.axvspan(stimulus['start_time'], stimulus['end_time'], color=stimulus['color'], alpha=0.5)\n",
        "\n",
        "\n",
        "def plot_running(trial, ax):\n",
        "    '''\n",
        "    plot running speed for trial on specified axes\n",
        "    '''\n",
        "    trial_running_speed = experiment_dataset.running_speed.query('timestamps >= {} and timestamps <= {} '.format(float(trial['start_time']), float(trial['stop_time'])))\n",
        "    ax.plot(\n",
        "        trial_running_speed['timestamps'],\n",
        "        trial_running_speed['speed'],\n",
        "        color='black'\n",
        "    )\n",
        "    #ax.set_title('running speed')\n",
        "    #ax.set_ylabel('speed (cm/s)')\n",
        "\n",
        "\n",
        "def plot_licks(trial, ax):\n",
        "    '''\n",
        "    plot licks as black dots on specified axis\n",
        "    '''\n",
        "    trial_licks = experiment_dataset.licks.query('timestamps >= {} and timestamps <= {} '.format(float(trial['start_time']), float(trial['stop_time'])))\n",
        "    ax.plot(\n",
        "        trial_licks['timestamps'],\n",
        "        np.zeros_like(trial_licks['timestamps']),\n",
        "        marker = 'o',\n",
        "        linestyle = 'none',\n",
        "        color='black'\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_rewards(trial, ax):\n",
        "    '''\n",
        "    plot rewards as blue diamonds on specified axis\n",
        "    '''\n",
        "    trial_rewards = experiment_dataset.rewards.query('timestamps >= {} and timestamps <= {} '.format(float(trial['start_time']), float(trial['stop_time'])))\n",
        "    ax.plot(\n",
        "        trial_rewards['timestamps'],\n",
        "        np.zeros_like(trial_rewards['timestamps']),\n",
        "        marker = 'd',\n",
        "        linestyle = 'none',\n",
        "        color='blue',\n",
        "        markersize = 10,\n",
        "        alpha = 0.25\n",
        "    )\n",
        "\n",
        "def plot_pupil(trial, ax):\n",
        "    '''\n",
        "    plot pupil area on specified axis\n",
        "    '''\n",
        "    trial_eye_tracking = experiment_dataset.eye_tracking.query('timestamps >= {} and timestamps <= {} '.format(float(trial['start_time']), float(trial['stop_time'])))\n",
        "    ax.plot(\n",
        "        trial_eye_tracking['timestamps'],\n",
        "        trial_eye_tracking['pupil_area'],\n",
        "        color='black'\n",
        "    )\n",
        "    #ax.set_title('pupil area')\n",
        "    #ax.set_ylabel('pupil area\\n')\n",
        "\n",
        "# note: this is the tidy data format from the function above\n",
        "def plot_dff(trial, ax):\n",
        "    '''\n",
        "    plot each cell's dff response for a given trial\n",
        "    '''\n",
        "    trial_dff_traces = experiment_dataset.tidy_dff_traces.query('timestamps >= {} and timestamps <= {} '.format(float(trial['start_time']), float(trial['stop_time'])))\n",
        "    for cell_specimen_id in experiment_dataset.tidy_dff_traces['cell_specimen_id'].unique():\n",
        "        ax.plot(\n",
        "            trial_dff_traces.query('cell_specimen_id == @cell_specimen_id')['timestamps'],\n",
        "            trial_dff_traces.query('cell_specimen_id == @cell_specimen_id')['dff']\n",
        "        )\n",
        "        #ax.set_title('deltaF/F responses')\n",
        "        #ax.set_ylabel('dF/F')\n",
        "\n",
        "## Not currently using this function- plotting individually below and adjusting axes, legend\n",
        "## If using this function, the legend shapes for rewards and licks do not show up properly\n",
        "def make_trial_plot(trial):\n",
        "    '''\n",
        "    combine all plots for a given trial\n",
        "    '''\n",
        "    fig, axes = plt.subplots(4, 1, figsize = (15, 8), sharex=True)\n",
        "\n",
        "    for ax in axes:\n",
        "        plot_stimuli(trial, ax)\n",
        "\n",
        "    plot_running(trial, axes[0])\n",
        "\n",
        "    plot_licks(trial, axes[1])\n",
        "    plot_rewards(trial, axes[1])\n",
        "\n",
        "    axes[1].set_title('licks and rewards')\n",
        "    axes[1].set_yticks([])\n",
        "    axes[1].legend(['licks','rewards'],frameon = False);\n",
        "\n",
        "\n",
        "    plot_pupil(trial, axes[2])\n",
        "\n",
        "    plot_dff(trial, axes[3])\n",
        "\n",
        "    axes[3].set_xlabel('time in session (seconds)')\n",
        "    fig.tight_layout()\n",
        "    return fig, axes"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tHjvAIKqUXnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trialtype 1: What type of trial is this?"
      ],
      "metadata": {
        "id": "eK10qP_VCAyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Plotting Code\n",
        "# Plotting hit trial\n",
        "trial = experiment_dataset.trials.query('hit').sample(random_state = 12)\n",
        "print('trial id chosen:', trial.index[0])\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize = (15, 8), sharex=True)\n",
        "\n",
        "for ax in axes:\n",
        "  plot_stimuli(trial, ax)\n",
        "\n",
        "  plot_running(trial, axes[0])\n",
        "  axes[0].set_title('running speed')\n",
        "  axes[0].set_ylabel('speed (cm/s)')\n",
        "\n",
        "  plot_licks(trial, axes[1])\n",
        "  plot_rewards(trial, axes[1])\n",
        "  axes[1].set_title('licks and rewards')\n",
        "  axes[1].set_yticks([])\n",
        "  axes[1].legend(['licks','rewards'], frameon = False);\n",
        "\n",
        "  plot_pupil(trial, axes[2])\n",
        "  axes[2].set_title('pupil area')\n",
        "  axes[2].set_ylabel('pupil area')\n",
        "\n",
        "  plot_dff(trial, axes[3])\n",
        "  axes[3].set_title('deltaF/F responses')\n",
        "  axes[3].set_ylabel('dF/F')\n",
        "\n",
        "  axes[3].set_xlabel('time in session (seconds)')\n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "V_81-ZmCUp3m",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trial"
      ],
      "metadata": {
        "id": "c3upRMNSmhwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trialtype 2: What type of trial is this?"
      ],
      "metadata": {
        "id": "ew4w-OMjY7Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Plotting Code\n",
        "trial = experiment_dataset.trials.query('miss').sample(random_state = 12)\n",
        "print('trial id chosen:', trial.index[0])\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize = (15, 8), sharex=True)\n",
        "\n",
        "for ax in axes:\n",
        "  plot_stimuli(trial, ax)\n",
        "\n",
        "  plot_running(trial, axes[0])\n",
        "  axes[0].set_title('running speed')\n",
        "  axes[0].set_ylabel('speed (cm/s)')\n",
        "\n",
        "  plot_licks(trial, axes[1])\n",
        "  plot_rewards(trial, axes[1])\n",
        "  axes[1].set_title('licks and rewards')\n",
        "  axes[1].set_yticks([])\n",
        "  axes[1].legend(['licks','rewards'], frameon = False);\n",
        "\n",
        "  plot_pupil(trial, axes[2])\n",
        "  axes[2].set_title('pupil area')\n",
        "  axes[2].set_ylabel('pupil area')\n",
        "\n",
        "  plot_dff(trial, axes[3])\n",
        "  axes[3].set_title('deltaF/F responses')\n",
        "  axes[3].set_ylabel('dF/F')\n",
        "\n",
        "  axes[3].set_xlabel('time in session (seconds)')\n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "4jDDPEXUQTwn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trialtype 3: What type of trial is this?"
      ],
      "metadata": {
        "id": "mFiFMJ3XZAHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Plotting Code\n",
        "trial = experiment_dataset.trials.query('false_alarm').sample(random_state = 12)\n",
        "print('trial id chosen:', trial.index[0])\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize = (15, 8), sharex=True)\n",
        "\n",
        "for ax in axes:\n",
        "  plot_stimuli(trial, ax)\n",
        "\n",
        "  plot_running(trial, axes[0])\n",
        "  axes[0].set_title('running speed')\n",
        "  axes[0].set_ylabel('speed (cm/s)')\n",
        "\n",
        "  plot_licks(trial, axes[1])\n",
        "  plot_rewards(trial, axes[1])\n",
        "  axes[1].set_title('licks and rewards')\n",
        "  axes[1].set_yticks([])\n",
        "  axes[1].legend(['licks','rewards'], frameon = False);\n",
        "\n",
        "  plot_pupil(trial, axes[2])\n",
        "  axes[2].set_title('pupil area')\n",
        "  axes[2].set_ylabel('pupil area')\n",
        "\n",
        "  plot_dff(trial, axes[3])\n",
        "  axes[3].set_title('deltaF/F responses')\n",
        "  axes[3].set_ylabel('dF/F')\n",
        "\n",
        "  axes[3].set_xlabel('time in session (seconds)')\n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "o8kbu49mCyNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trialtype 4: What type of trial is this?"
      ],
      "metadata": {
        "id": "lNl_ZjurZELa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Plotting Code\n",
        "trial = experiment_dataset.trials.query('correct_reject').sample(random_state = 12)\n",
        "print('trial id chosen:', trial.index[0])\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize = (15, 8), sharex=True)\n",
        "\n",
        "for ax in axes:\n",
        "  plot_stimuli(trial, ax)\n",
        "\n",
        "  plot_running(trial, axes[0])\n",
        "  axes[0].set_title('running speed')\n",
        "  axes[0].set_ylabel('speed (cm/s)')\n",
        "\n",
        "  plot_licks(trial, axes[1])\n",
        "  plot_rewards(trial, axes[1])\n",
        "  axes[1].set_title('licks and rewards')\n",
        "  axes[1].set_yticks([])\n",
        "  axes[1].legend(['licks','rewards'], frameon = False);\n",
        "\n",
        "  plot_pupil(trial, axes[2])\n",
        "  axes[2].set_title('pupil area')\n",
        "  axes[2].set_ylabel('pupil area')\n",
        "\n",
        "  plot_dff(trial, axes[3])\n",
        "  axes[3].set_title('deltaF/F responses')\n",
        "  axes[3].set_ylabel('dF/F')\n",
        "\n",
        "  axes[3].set_xlabel('time in session (seconds)')\n",
        "  fig.tight_layout()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5ALNek38D8kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåü Just for fun üåÄ"
      ],
      "metadata": {
        "id": "25lonHYTYnCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this for a fun message + image\n",
        "from IPython.display import HTML\n",
        "print('Great work today!')\n",
        "HTML('<img src=\"https://media.giphy.com/media/jkvmzOg3LtpF6/giphy.gif\">')"
      ],
      "metadata": {
        "id": "3tVh1Fd7Yoaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## üöÄ Interested in more? See this online tutorial with code\n",
        "\n",
        "https://allenswdb.github.io/physiology/ophys/visual-behavior/VBO-Tutorial-Compare_trial_types.html#compare-trial-types\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gf3drocye7PM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üîé üåü Additional Visualizations & Code\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fxnt9Rs9UWMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1Ô∏è‚É£  SST Neuron - is activity related to behavior?"
      ],
      "metadata": {
        "id": "Vy0StLLtwP5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter data to select subset - get `ophys_experiment_id`s corresponding to specific experimental conditions by filtering the table using the columns: <br>\n",
        "\n",
        "* mice from the Sst-IRES-Cre Driver Line: `cre_line`\n",
        "* `session_number` to identify experiments from the first session with the novel images\n",
        "  * always has a `session_type` starting with `OPHYS_4`\n",
        "  * use  abbreviated `session_number` column (agnostic to which specific image set was used)\n",
        "* `prior_exposures_to_image_set`: select a session that was the first day with the novel image set (not a retake of the same `session_type`)"
      ],
      "metadata": {
        "id": "gROy3tgKGaNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all Sst experiments for ophys session 4 (novel images)\n",
        "selected_experiment_table = ophys_experiment_table[(ophys_experiment_table.cre_line=='Sst-IRES-Cre')&\n",
        "                        (ophys_experiment_table.session_number==4) &\n",
        "                        (ophys_experiment_table.prior_exposures_to_image_set==0)]\n",
        "print('Number of experiments: {}'.format(len(selected_experiment_table)))"
      ],
      "metadata": {
        "id": "yiJfY4vtGGct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that any given experiment (defined by its ophys_experiment_id) contains data from only one imaging plane, in one session. There can be multiple experiments (imaging planes) recorded in the same imaging session if the multi-plane 2-photon microscope was used, but there can never be multiple sessions for a given ophys_experiment_id."
      ],
      "metadata": {
        "id": "UC3_rY8qHIUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of unique sessions: {}'.format(len(selected_experiment_table['ophys_session_id'].unique())))"
      ],
      "metadata": {
        "id": "tojxjh8nHCgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will randomly select data from an experiment- I've already pre-selected one below for us."
      ],
      "metadata": {
        "id": "lOCycZEhH3DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data for this ophys experiment from the cache\n",
        "ophys_experiment_id = 957759562\n",
        "ophys_experiment = cache.get_behavior_ophys_experiment(ophys_experiment_id)"
      ],
      "metadata": {
        "id": "RrqkTeoNH2mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `get_behavior_ophys_experiment()` method returns a python object containing all data and metadata for the provided `ophys_experiment_id`."
      ],
      "metadata": {
        "id": "XtMdH1XMIHUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ophys_experiment.metadata"
      ],
      "metadata": {
        "id": "kFB4pFUvIJRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next steps, we want to combine various sources of data into a single plot: <br>\n",
        "* `dff_traces`\n",
        "* `events`\n",
        "* `running_speed`\n",
        "* `pupil_area`\n",
        "* `stimulus_presentations`"
      ],
      "metadata": {
        "id": "VH7eVO7teLbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Review: Images\n",
        "`stimulus_presentations` has some NaN values. We need to remove those rows of the data because they correspond to other conditions we aren't interested in (initial_gray_screen_5min, natural_movie, etc)"
      ],
      "metadata": {
        "id": "AquVjQnDesuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# review this data and see NaNs\n",
        "ophys_experiment.stimulus_presentations"
      ],
      "metadata": {
        "id": "fPHsaoztfrNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many unique options are there?\n",
        "ophys_experiment.stimulus_presentations['image_name'].unique()"
      ],
      "metadata": {
        "id": "6P24axw7IqCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove these from the data we will work with, there are multiple options:\n",
        "1. Remove rows with NaNs in our column of interest\n",
        "2. Filter based on the `stimulus_block_name` column for `change_detection_behavior`"
      ],
      "metadata": {
        "id": "oNAhKnjCfVak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Select data that are not null (all except NaNs) in image_name col\n",
        "# dataframe\n",
        "all_stim = ophys_experiment.stimulus_presentations\n",
        "\n",
        "# remove the Nans- effectively selecting only stimulus_block_name that is change_detection_behavior\n",
        "all_stim = all_stim[all_stim['image_name'].notnull()]"
      ],
      "metadata": {
        "id": "p20g7WWxe7RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the results before proceeding"
      ],
      "metadata": {
        "id": "R8lW_aFvgu45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_stim['image_name'].unique()"
      ],
      "metadata": {
        "id": "LOYOA9lffx2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stim['stimulus_block_name'].unique()"
      ],
      "metadata": {
        "id": "5ffChDNaf1Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ the `all_stim` dataframe is the one we will use in the code below"
      ],
      "metadata": {
        "id": "8APuhepCOTym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Another example of creating the same dataframe from above"
      ],
      "metadata": {
        "id": "nk5yoQnwmP1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2: Filter based on stimulus_block_name\n",
        "# dataframe\n",
        "stim = ophys_experiment.stimulus_presentations\n",
        "\n",
        "# remove the Nans- effectively selecting only stimulus_block_name that is change_detection_behavior\n",
        "stim_another_way = stim[stim['stimulus_block_name'] == 'change_detection_behavior']"
      ],
      "metadata": {
        "id": "lumYyH65gRdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the results before proceeding"
      ],
      "metadata": {
        "id": "1pjsxJM6gpsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stim_another_way['image_name'].unique()"
      ],
      "metadata": {
        "id": "epRnsmDJghKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stim_another_way['stimulus_block_name'].unique()"
      ],
      "metadata": {
        "id": "BGjGLmnvgnog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Prep: Defining Colors for Each Image\n",
        "Data preparation for plotting- we will add a list of colors for each image. This will appear as a vertical bar on our plots to indicate the time the image was shown, and to visually identify when images changed or stayed the same."
      ],
      "metadata": {
        "id": "2FUqCE8_hZlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Code\n",
        "# create a list of all unique stimuli presented in this experiment\n",
        "unique_stimuli = [stimulus for stimulus in all_stim['image_name'].unique()]\n",
        "\n",
        "# create a colormap with each unique image having its own color\n",
        "colormap = {image_name: sns.color_palette()[image_number] for image_number, image_name in enumerate(np.sort(unique_stimuli))}\n",
        "colormap['omitted'] = (1,1,1) # set omitted stimulus to white color\n",
        "\n",
        "# add the colors for each image to the stimulus presentations table in the dataset\n",
        "stimulus_presentations = all_stim\n",
        "stimulus_presentations['color'] = all_stim['image_name'].map(lambda image_name: colormap[image_name])"
      ],
      "metadata": {
        "id": "50ytpgXihWRo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is called [list comprehension](https://www.geeksforgeeks.org/python-list-comprehension/)"
      ],
      "metadata": {
        "id": "H40yrDHRjDMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Walk through of the above cells- Optional"
      ],
      "metadata": {
        "id": "Sa2KzrKPPNnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of all unique stimuli presented in this experiment\n",
        "unique_stimuli = [stimulus for stimulus in all_stim['image_name'].unique()]\n",
        "unique_stimuli"
      ],
      "metadata": {
        "id": "M9YRCjJmh8Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a colormap with each unique image having its own color- this is a dict\n",
        "# note here we also use seaborn color palettes - sns\n",
        "colormap = {image_name: sns.color_palette()[image_number] for image_number, image_name in enumerate(np.sort(unique_stimuli))}\n",
        "colormap"
      ],
      "metadata": {
        "id": "TrJlhcVth-di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colormap['omitted'] = (1,1,1) # set omitted stimulus to white color\n",
        "colormap"
      ],
      "metadata": {
        "id": "MDqlCkpCjTwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These lines are also advanced and topics we haven't covered. `lambda` is used for an [anonymous function](https://www.geeksforgeeks.org/python-list-comprehension/) along with the [`.map`](https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.map.html) method in `pandas`"
      ],
      "metadata": {
        "id": "03uJ2vUum4DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the colors for each image to the stimulus presentations table in the dataset\n",
        "stimulus_presentations = all_stim\n",
        "stimulus_presentations['color'] = all_stim['image_name'].map(lambda image_name: colormap[image_name])"
      ],
      "metadata": {
        "id": "FRJGUJlokDRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Review Data: New Color Column\n",
        "You can review the dataframe `stimulus_presentations` to see what we did- we added a color column that has color info depending on the image."
      ],
      "metadata": {
        "id": "B6SEKGKKnXWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stimulus_presentations"
      ],
      "metadata": {
        "id": "o87MfqBFnUv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Plotting Functions\n",
        "\n",
        "This is code to define individual functions for each type of the data we want to plot: <br>\n",
        "* `dff_traces` - calcium florescence signal\n",
        "* `events` - timing and magnitude of calcium signals\n",
        "  * exclude prolonged calcium transients that may contaminate neural responses to subsequent stimuli\n",
        "* `running speed` - running speed (cm/s)\n",
        "* `pupil area` - pupil area (px sq)\n",
        "* `licks` - timing of licking behavior\n",
        "* `rewards` - timing of reward delivery\n",
        "* `stimuli` - color coded images for plot\n",
        "\n",
        "This enables us to just reuse the code to make the plot below, but select different cells to plot!\n"
      ],
      "metadata": {
        "id": "FCZ0Y1Sajx23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Functions\n",
        "# function to plot dff traces\n",
        "def plot_dff_trace(ax, cell_specimen_id, initial_time, final_time):\n",
        "    '''\n",
        "        ax: axis on which to plot\n",
        "        cell_specimen_id: id of the cell to plot\n",
        "        intial_time: initial time to plot from\n",
        "        final_time: final time to plot to\n",
        "    '''\n",
        "    # create a dataframe using dff trace from one selected cell\n",
        "    data = {'dff': ophys_experiment.dff_traces.loc[cell_specimen_id]['dff'],\n",
        "        'timestamps': ophys_experiment.ophys_timestamps}\n",
        "    df = pd.DataFrame(data)\n",
        "    dff_trace_sample = df[(df.timestamps >= initial_time) & (df.timestamps <= final_time)]\n",
        "    ax.plot(dff_trace_sample['timestamps'], dff_trace_sample['dff']/dff_trace_sample['dff'].max())\n",
        "\n",
        "# function to plot events traces\n",
        "def plot_events_trace(ax, cell_specimen_id, initial_time, final_time):\n",
        "    # create a dataframe using events trace from one selected cell\n",
        "    data = {'events': ophys_experiment.events.loc[cell_specimen_id].events,\n",
        "        'timestamps': ophys_experiment.ophys_timestamps}\n",
        "    df = pd.DataFrame(data)\n",
        "    events_trace_sample = df[(df.timestamps >= initial_time) & (df.timestamps <= final_time)]\n",
        "    ax.plot(events_trace_sample['timestamps'], events_trace_sample['events']/events_trace_sample['events'].max())\n",
        "\n",
        "# function to plot running speed\n",
        "def plot_running(ax, initial_time, final_time):\n",
        "    running_sample = ophys_experiment.running_speed.copy()\n",
        "    running_sample = running_sample[(running_sample.timestamps >= initial_time) & (running_sample.timestamps <= final_time)]\n",
        "    ax.plot(running_sample['timestamps'], running_sample['speed']/running_sample['speed'].max(),\n",
        "            '--', color = 'gray', linewidth = 1)\n",
        "\n",
        "# function to plot pupil diameter\n",
        "def plot_pupil(ax, initial_time, final_time):\n",
        "    pupil_sample = ophys_experiment.eye_tracking.copy()\n",
        "    pupil_sample = pupil_sample[(pupil_sample.timestamps >= initial_time) &\n",
        "                                (pupil_sample.timestamps <= final_time)]\n",
        "    ax.plot(pupil_sample['timestamps'], pupil_sample['pupil_width']/pupil_sample['pupil_width'].max(),\n",
        "            color = 'gray', linewidth = 1)\n",
        "\n",
        "# function to plot licks\n",
        "def plot_licks(ax, initial_time, final_time):\n",
        "    licking_sample = ophys_experiment.licks.copy()\n",
        "    licking_sample = licking_sample[(licking_sample.timestamps >= initial_time) &\n",
        "                                    (licking_sample.timestamps <= final_time)]\n",
        "    ax.plot(licking_sample['timestamps'], np.zeros_like(licking_sample['timestamps']),\n",
        "            marker = 'o', markersize = 3, color = 'black', linestyle = 'none')\n",
        "\n",
        "# function to plot rewards\n",
        "def plot_rewards(ax, initial_time, final_time):\n",
        "    rewards_sample = ophys_experiment.rewards.copy()\n",
        "    rewards_sample = rewards_sample[(rewards_sample.timestamps >= initial_time) &\n",
        "                                    (rewards_sample.timestamps <= final_time)]\n",
        "    ax.plot(rewards_sample['timestamps'], np.zeros_like(rewards_sample['timestamps']),\n",
        "            marker = 'd', color = 'blue', linestyle = 'none', markersize = 12, alpha = 0.5)\n",
        "\n",
        "# function to plot stimuli\n",
        "def plot_stimuli(ax, initial_time, final_time):\n",
        "    stimulus_presentations_sample = stimulus_presentations.copy()\n",
        "    stimulus_presentations_sample = stimulus_presentations_sample[(stimulus_presentations_sample.end_time >= initial_time) & (stimulus_presentations_sample.start_time <= final_time)]\n",
        "    for idx, stimulus in stimulus_presentations_sample.iterrows():\n",
        "        ax.axvspan(stimulus['start_time'], stimulus['end_time'], color=stimulus['color'], alpha=0.25)"
      ],
      "metadata": {
        "id": "VJwHmcPXjkJQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of cell_specimen_ids using the index of cell_specimen_table- we choose one below\n",
        "cell_specimen_ids = ophys_experiment.cell_specimen_table.index.values\n",
        "cell_specimen_ids"
      ],
      "metadata": {
        "id": "RSExgrn5pHEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cell_specimen_ids)"
      ],
      "metadata": {
        "id": "eausq0r8nBEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting code\n",
        "\n",
        "# change the id here whenever you want to generate a new plot\n",
        "cell_id = cell_specimen_ids[6]\n",
        "\n",
        "initial_time = 820 # start time in seconds\n",
        "final_time = 860 # stop time in seconds\n",
        "\n",
        "fig, ax = plt.subplots(2,1,figsize = (15,7))\n",
        "\n",
        "plot_dff_trace(ax[0], cell_specimen_ids[3], initial_time, final_time)\n",
        "plot_events_trace(ax[0], cell_specimen_ids[3], initial_time, final_time)\n",
        "plot_stimuli(ax[0], initial_time, final_time)\n",
        "ax[0].set_ylabel('normalized response magnitude')\n",
        "ax[0].set_yticks([])\n",
        "ax[0].legend(['dff trace', 'event'], bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, frameon = False)\n",
        "\n",
        "plot_running(ax[1], initial_time, final_time)\n",
        "plot_pupil(ax[1], initial_time, final_time)\n",
        "plot_licks(ax[1], initial_time, final_time)\n",
        "plot_rewards(ax[1], initial_time, final_time)\n",
        "plot_stimuli(ax[1], initial_time, final_time)\n",
        "\n",
        "ax[1].set_yticks([])\n",
        "ax[1].legend(['running speed', 'pupil','licks', 'rewards'],bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, frameon = False);"
      ],
      "metadata": {
        "id": "BA5ZHPHbZiL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "What do you see in this plot? </div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "cellView": "form",
        "id": "cY7dKpydqwv2",
        "outputId": "7bd20d1f-e017-4ec9-a92d-c9c704833ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "What do you see in this plot? </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden\n",
        "# This SST neuron (13-14 minutes into session)::\n",
        "# active during our experiment but its activity does not appear to be reliably locked to image presentations\n",
        "# might follow animal's running speed - could be modulated by running instead"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yGjtLiohvrwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Which images üåá üéÜ üèû  were shown on the trials above?"
      ],
      "metadata": {
        "id": "7FxPpas9Vue_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we want to know which images were shown here?"
      ],
      "metadata": {
        "id": "CnVMjuf0ud1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # from the stimulus presentation function to plot\n",
        "stimulus_presentations_plot = stimulus_presentations.copy()\n",
        "stimulus_presentations_plot = stimulus_presentations_plot[(stimulus_presentations_plot.end_time >= initial_time) & (stimulus_presentations_plot.start_time <= final_time)]\n",
        "stimulus_presentations_plot.image_name.unique()"
      ],
      "metadata": {
        "id": "ubs0cYH8ugMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the table with this info- we an then use indices to find the data to plot for each image."
      ],
      "metadata": {
        "id": "mACboGROu4_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ophys_experiment.stimulus_templates"
      ],
      "metadata": {
        "id": "nR8RC7ELu0xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im106 is index 1\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[1]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "9b2fHRntu_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im054 is index 5\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[5]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "OtOFw6KnvFgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im031 is index 6\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[6]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "PSkmXjxVvVfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Dff vs events"
      ],
      "metadata": {
        "id": "aoXChN0WV8bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden Code - dff and events\n",
        "# plot dff and events traces overlaid from the cell selected above\n",
        "fig, ax = plt.subplots(1,1, figsize = (10,2))\n",
        "ax.plot(ophys_experiment.ophys_timestamps, ophys_experiment.dff_traces.loc[cell_id, 'dff'], label='dff')\n",
        "ax.plot(ophys_experiment.ophys_timestamps, ophys_experiment.events.loc[cell_id, 'events'], label='events')\n",
        "ax.set_xlabel('time (seconds)')\n",
        "ax.set_ylabel('trace magnitude')\n",
        "ax.set_title('cell_specimen_id = '+str(cell_specimen_id))\n",
        "ax.legend();"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M1wqxEXmttf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2Ô∏è‚É£ VIP Neuron - is activity related to behavior?"
      ],
      "metadata": {
        "id": "WMxssFCPwCjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter data to select subset - get `ophys_experiment_id`s corresponding to specific experimental conditions by filtering the table using the columns: <br>\n",
        "\n",
        "* mice from the Vip-IRES-Cre Driver Line: `cre_line`\n",
        "* `session_number` to identify experiments from the first session with the novel images\n",
        "  * always has a `session_type` starting with `OPHYS_1`\n",
        "  * use  abbreviated `session_number` column (agnostic to which specific image set was used)\n",
        "\n",
        "This will differ from the previous as we will pick from a session with `familiar` images"
      ],
      "metadata": {
        "id": "rJaI7s2pwe0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a Vip experiment with familiar images (session_number = 1, 2, or 3)\n",
        "selected_experiment_table = ophys_experiment_table[(ophys_experiment_table.cre_line=='Vip-IRES-Cre')&\n",
        "                        (ophys_experiment_table.session_number==1)]\n",
        "\n",
        "# load the experiment data from the cache\n",
        "ophys_experiment = cache.get_behavior_ophys_experiment(selected_experiment_table.index.values[1])\n",
        "# get the cell IDs\n",
        "cell_specimen_ids = ophys_experiment.cell_specimen_table.index.values # a list of all cell ids"
      ],
      "metadata": {
        "id": "gVkMUJSdpYyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Prep: Defining Colors for Each Image\n",
        "Review `stimulus_presentations` because some values are NaN. We need to remove those rows of the data because they correspond to other conditions we aren't interested in (initial_gray_screen_5min, natural_movie, etc)"
      ],
      "metadata": {
        "id": "MCo_El0Jw535"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe from the metadata\n",
        "new_stim = ophys_experiment.stimulus_presentations\n",
        "\n",
        "# remove the Nans- effectively selecting only stimulus_block_name that is change_detection_behavior\n",
        "new_stim = new_stim[new_stim['image_name'].notnull()]"
      ],
      "metadata": {
        "id": "HncF8LG0wwed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same as above- all in one cell now\n",
        "\n",
        "# create a list of all unique stimuli presented in this experiment\n",
        "unique_stimuli = [stimulus for stimulus in new_stim['image_name'].unique()]\n",
        "\n",
        "# create a colormap with each unique image having its own color\n",
        "colormap = {image_name: sns.color_palette()[image_number] for image_number, image_name in enumerate(np.sort(unique_stimuli))}\n",
        "colormap['omitted'] = (1,1,1) # set omitted stimulus to white color\n",
        "\n",
        "# add the colors for each image to the stimulus presentations table in the dataset\n",
        "stimulus_presentations = new_stim\n",
        "stimulus_presentations['color'] = new_stim['image_name'].map(lambda image_name: colormap[image_name])"
      ],
      "metadata": {
        "id": "OnEi-BmHxBsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Neural Activity & Behavior\n",
        "Now we plot! Our functions were already defined above, so can just be called here"
      ],
      "metadata": {
        "id": "EuOjuBKvxKZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can plot the same information for a different cell in the dataset\n",
        "\n",
        "# change the id here whenever you want to generate a new plot\n",
        "cell_id = cell_specimen_ids[5]\n",
        "\n",
        "initial_time = 580 # start time in seconds\n",
        "final_time = 620 # stop time in seconds\n",
        "fig, ax = plt.subplots(2,1,figsize = (15,7))\n",
        "\n",
        "plot_dff_trace(ax[0], cell_id, initial_time, final_time)\n",
        "plot_events_trace(ax[0], cell_id, initial_time, final_time)\n",
        "plot_stimuli(ax[0], initial_time, final_time)\n",
        "ax[0].set_ylabel('normalized response magnitude')\n",
        "ax[0].set_yticks([])\n",
        "ax[0].set_title('cell_specimen_id = '+str(cell_id))\n",
        "ax[0].legend(['dff trace', 'events trace'], bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, frameon = False)\n",
        "\n",
        "plot_running(ax[1], initial_time, final_time)\n",
        "plot_pupil(ax[1], initial_time, final_time)\n",
        "plot_licks(ax[1], initial_time, final_time)\n",
        "plot_rewards(ax[1], initial_time, final_time)\n",
        "plot_stimuli(ax[1], initial_time, final_time)\n",
        "\n",
        "ax[1].set_yticks([])\n",
        "ax[1].set_xlabel('time (secs)')\n",
        "ax[1].legend(['running speed', 'pupil','licks', 'rewards'],bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, frameon = False);"
      ],
      "metadata": {
        "id": "l2SUdAX5xKC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Task\n",
        "from IPython.display import HTML\n",
        "\n",
        "alert_info = '''\n",
        "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
        "  <h4 class=\"alert-heading\">Task</h4>\n",
        "What do you see in this plot? </div>\n",
        "'''\n",
        "\n",
        "display(HTML('<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">'))\n",
        "display(HTML(alert_info))"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "1kLBGChbVf9Q",
        "outputId": "d00a3795-3677-4ed6-87d2-d41ce778c1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<link href=\"https://nbviewer.org/static/build/styles.css\" rel=\"stylesheet\">"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style= \"font-size: 20px\"; class=\"alert alert-info\" role=\"alert\">\n",
              "  <h4 class=\"alert-heading\">Task</h4>\n",
              "What do you see in this plot? </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hidden\n",
        "# This VIP neuron (9-10 minutes into session):\n",
        "# active during our experiment but its activity does not appear to be reliably locked to image presentations as well\n",
        "# Aligning neural activity to different behavioral or experimental events might reveal what this neuron is driven by"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j6rjt0dmy53N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Which images üåá üéÜ üèû were shown on the trials above?\n",
        "What if we want to know which images were shown here?"
      ],
      "metadata": {
        "id": "B57c079ay53O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From the stimulus presentation function to plot\n",
        "stimulus_presentations_plot = stimulus_presentations.copy()\n",
        "stimulus_presentations_plot = stimulus_presentations_plot[(stimulus_presentations_plot.end_time >= initial_time) & (stimulus_presentations_plot.start_time <= final_time)]\n",
        "stimulus_presentations_plot.image_name.unique()"
      ],
      "metadata": {
        "id": "bKFkHdTGxb-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the table with this info- we an then use indices to find the data to plot for each image."
      ],
      "metadata": {
        "id": "nmjD8SbFy53O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ophys_experiment.stimulus_templates"
      ],
      "metadata": {
        "id": "0Wv3O5lqx2mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im061 is index 3\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[3]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "NruV6bBSyEC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im077 is index 1\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[1]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "p7RBIWGLyJnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im062 is index 5\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[5]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "7H1Ed5yxyNet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im085 is index 6\n",
        "stimulus_templates = ophys_experiment.stimulus_templates.copy()\n",
        "stimuli = stimulus_templates.index.values\n",
        "plt.imshow(stimulus_templates.loc[stimuli[6]]['unwarped'], cmap='gray');"
      ],
      "metadata": {
        "id": "4I4ua8fKyVIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Example neural dataset provided in Seaborn (sns)"
      ],
      "metadata": {
        "id": "vZBl5ppYXZmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "# Load an example dataset with long-form data\n",
        "fmri = sns.load_dataset(\"fmri\")\n",
        "\n",
        "# Plot the responses for different events and regions\n",
        "sns.lineplot(x=\"timepoint\", y=\"signal\",\n",
        "             hue=\"region\", style=\"event\",\n",
        "             data=fmri)"
      ],
      "metadata": {
        "id": "e7_PD5xqro7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "\n",
        "# Technical notes & credits üî©üëè üßë\n",
        "\n",
        "\n",
        "Much more information can be found in the [Allen Brain Institute whitepaper](https://brainmapportal-live-4cc80a57cd6e400d854-f7fdcae.divio-media.net/filer_public/4e/be/4ebe2911-bd38-4230-86c8-01a86cfd758e/visual_behavior_2p_technical_whitepaper.pdf) as well as in their <a href=\"http://allensdk.readthedocs.io/en/latest/visual_behavior_optical_physiology.html\"> documentation</a>.\n",
        "\n",
        "This notebook was developed from the [Allen Institute Notebooks](https://allensdk.readthedocs.io/en/latest/visual_behavior_optical_physiology.html) and [Neuromatch Academy](https://compneuro.neuromatch.io/projects/neurons/README.html#allen-institute)."
      ],
      "metadata": {
        "id": "Bu7-AZM1YvS0"
      }
    }
  ]
}